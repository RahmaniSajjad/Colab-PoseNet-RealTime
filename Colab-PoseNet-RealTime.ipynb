{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install mediapipe opencv-python tensorflow"
      ],
      "metadata": {
        "id": "vBQQv4_D4GAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import cv2  # OpenCV for image processing\n",
        "import mediapipe as mp  # MediaPipe for human pose detection\n",
        "import numpy as np  # NumPy for array manipulations\n",
        "from base64 import b64decode, b64encode  # Base64 encoding/decoding for handling image data\n",
        "from google.colab.output import eval_js  # JavaScript execution in Google Colab\n",
        "from IPython.display import display, Javascript  # Display JavaScript in Colab environment\n",
        "import tensorflow as tf  # TensorFlow for building and running the CNN model\n",
        "from tensorflow.keras.models import Sequential  # Sequential model for CNN\n",
        "from tensorflow.keras.layers import Dense  # Dense layers for the neural network"
      ],
      "metadata": {
        "id": "Dpr7lCk84Q-C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN Model for Pose Classification\n",
        "def build_cnn_model():\n",
        "    \"\"\"\n",
        "    This function builds a simple CNN model using Keras.\n",
        "    The input shape is 99, which corresponds to 33 pose landmarks, each with 3 coordinates (x, y, z).\n",
        "    The model consists of 3 dense layers, with the last layer classifying into 6 possible pose classes.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(99,)),  # First dense layer with 128 units and ReLU activation\n",
        "        Dense(64, activation='relu'),  # Second dense layer with 64 units and ReLU activation\n",
        "        Dense(32, activation='relu'),  # Third dense layer with 32 units and ReLU activation\n",
        "        Dense(6, activation='softmax')  # Output layer with softmax activation for 6 pose classes\n",
        "    ])\n",
        "    # Compile the model using Adam optimizer and categorical crossentropy loss function\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "hCbBkrYz4Vxp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MediaPipe Pose Detection\n",
        "mp_pose = mp.solutions.pose  # Load the MediaPipe Pose solution\n",
        "pose = mp_pose.Pose()  # Create a Pose object for detection\n",
        "mp_drawing = mp.solutions.drawing_utils  # Utility for drawing the landmarks on the image"
      ],
      "metadata": {
        "id": "kOS0dpVF4cBq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to capture image from webcam\n",
        "def capture_image():\n",
        "    \"\"\"\n",
        "    This function runs JavaScript to access the user's webcam, captures an image,\n",
        "    and returns the image as a base64-encoded string.\n",
        "    \"\"\"\n",
        "    js = Javascript('''\n",
        "        async function capture() {\n",
        "            // Create a video element to capture the webcam feed\n",
        "            const video = document.createElement('video');\n",
        "            // Access the webcam stream\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Set the dimensions of the video frame\n",
        "            video.width = 320;\n",
        "            video.height = 240;\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.width;\n",
        "            canvas.height = video.height;\n",
        "            const context = canvas.getContext('2d');\n",
        "            // Draw the video frame onto the canvas\n",
        "            context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "            // Stop the video stream\n",
        "            stream.getTracks().forEach(track => track.stop());\n",
        "            video.remove();\n",
        "            // Return the image data as a base64-encoded string\n",
        "            return canvas.toDataURL('image/jpeg', 0.8);\n",
        "        }\n",
        "        capture();\n",
        "    ''')\n",
        "    display(js)  # Display the JavaScript in the Colab notebook\n",
        "    data = eval_js('capture()')  # Evaluate the JavaScript and get the captured image\n",
        "    return data"
      ],
      "metadata": {
        "id": "gY_cmVLN4gEp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert JavaScript image data to OpenCV image\n",
        "def js_to_image(js_data):\n",
        "    \"\"\"\n",
        "    This function decodes the base64 image string captured from the webcam\n",
        "    and converts it into an OpenCV-compatible image format (numpy array).\n",
        "    \"\"\"\n",
        "    img_bytes = b64decode(js_data.split(',')[1])  # Decode the base64 image string\n",
        "    img_arr = np.frombuffer(img_bytes, dtype=np.uint8)  # Convert it to a numpy array\n",
        "    img = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)  # Decode the image to OpenCV format (BGR)\n",
        "    return img"
      ],
      "metadata": {
        "id": "PeEkukKZ4kaZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess pose landmarks for CNN input\n",
        "def preprocess_landmarks(landmarks):\n",
        "    \"\"\"\n",
        "    This function extracts the x, y, and z coordinates from the detected landmarks\n",
        "    and flattens them into a 1D array for input into the CNN model.\n",
        "    \"\"\"\n",
        "    # Extract x, y, z coordinates from the pose landmarks and flatten them into a 1D array\n",
        "    pose_landmarks = np.array([[lm.x, lm.y, lm.z] for lm in landmarks]).flatten()\n",
        "    return pose_landmarks"
      ],
      "metadata": {
        "id": "2m2wfMra4oR-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process image for pose detection\n",
        "def process_image_with_pose_detection(image):\n",
        "    \"\"\"\n",
        "    This function takes an image, processes it using MediaPipe to detect human pose,\n",
        "    and returns the pose landmarks and the image with landmarks drawn on it.\n",
        "    \"\"\"\n",
        "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert the image from BGR to RGB format\n",
        "    results = pose.process(img_rgb)  # Perform pose detection using MediaPipe\n",
        "\n",
        "    if results.pose_landmarks:  # If pose landmarks are detected\n",
        "        # Draw the pose landmarks on the image\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "        # Preprocess the landmarks for CNN input\n",
        "        landmarks_array = preprocess_landmarks(results.pose_landmarks.landmark)\n",
        "        return landmarks_array, image  # Return the landmarks and the processed image\n",
        "    return None, image  # If no landmarks are detected, return None for landmarks"
      ],
      "metadata": {
        "id": "akTy1DgY4ryn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN model\n",
        "model = build_cnn_model()  # Build the CNN model for pose classification"
      ],
      "metadata": {
        "id": "49wZY5sN4wcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BnJUw-mwWeO"
      },
      "outputs": [],
      "source": [
        "# Capture and process images from webcam in a loop\n",
        "while True:\n",
        "    js_image = capture_image()  # Capture an image from the webcam using JavaScript\n",
        "    image = js_to_image(js_image)  # Convert the base64 image to OpenCV format\n",
        "\n",
        "    landmarks, processed_image = process_image_with_pose_detection(image)  # Process the image for pose detection\n",
        "\n",
        "    if landmarks is not None:  # If pose landmarks are detected\n",
        "        # Expand dimensions to make it compatible with CNN input (batch size 1)\n",
        "        input_data = np.expand_dims(landmarks, axis=0)\n",
        "\n",
        "        # Predict the pose class using the CNN model\n",
        "        prediction = model.predict(input_data)\n",
        "        pose_class = np.argmax(prediction)  # Get the predicted pose class\n",
        "\n",
        "        # Display the predicted pose class on the image\n",
        "        cv2.putText(processed_image, f'Pose Class: {pose_class}', (50, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "\n",
        "    # Encode the processed image to base64 format to display it in Colab\n",
        "    _, im_arr = cv2.imencode('.jpg', processed_image)\n",
        "    im_bytes = im_arr.tobytes()\n",
        "    im_b64 = b64encode(im_bytes).decode('utf-8')\n",
        "\n",
        "    # Use JavaScript to display the processed image with pose class prediction\n",
        "    display(Javascript(f'''\n",
        "        var img = new Image();\n",
        "        img.src = \"data:image/jpeg;base64,{im_b64}\";\n",
        "        document.body.appendChild(img);\n",
        "    '''))"
      ]
    }
  ]
}